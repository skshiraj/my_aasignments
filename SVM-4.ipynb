{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Tvnj5UblTy"
   },
   "source": [
    "## Task-D: Collinear features and their effect on linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qn_eOn2EblT3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMoYWIayblUB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfStXG4tblUI",
    "outputId": "ddf4eec6-7f53-4d28-914f-23133957d6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w  \\\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277   \n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364   \n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738   \n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720   \n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIIuomCkblUP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['target'], axis=1).values\n",
    "Y = data['target'].values\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydm98u3EblUU"
   },
   "source": [
    "### Doing perturbation test to check the presence of collinearity  \n",
    "\n",
    "#### Task: 1 Logistic Regression\n",
    "<pre>\n",
    "\n",
    "1. <b>Finding the Correlation between the features</b>\n",
    "    a. check the correlation between the features\n",
    "    b. plot heat map of correlation matrix using seaborn heatmap\n",
    "2. <b>Finding the best model for the given data</b>\n",
    "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         random search CV make sure you choose the alpha in log space)\n",
    "    c. Creat a new Logistic regression with the best alpha(search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "    \n",
    "3. <b>Getting the weights with the original data</b>\n",
    "    a. train the 'best_model' with X, Y\n",
    "    b. Check the accuracy of the model 'best_model_accuracy'\n",
    "    c. Get the weights W using best_model.coef_\n",
    "\n",
    "4. <b>Modifying original data</b>\n",
    "    a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)\n",
    "    b. Train the same 'best_model' with data (X', Y)\n",
    "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "    d. Get the weights W' using best_model.coef_\n",
    "    \n",
    "5. <b> Checking deviations in metric and weights </b>\n",
    "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "    c. print the top 4 features which have higher % change in weights compare to the other feature\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Task: 2 Linear SVM\n",
    "\n",
    "<pre>\n",
    "1. Do the same steps (2, 3, 4, 5) we have done in the above task 1.\n",
    "</pre>\n",
    "\n",
    "<strong><font color='red'>Do write the observations based on the results you get from the deviations of weights in both Logistic Regression and linear SVM</font></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Finding the Correlation between the features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. check the correlation between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.drop(['target','w'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.812458</td>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.996252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.812458</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>0.847163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x*x</th>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.997457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <td>0.996252</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x         y         z       x*x       2*y  2*z+3*x*x\n",
       "x          1.000000 -0.205926  0.812458  0.997947 -0.205926   0.996252\n",
       "y         -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123\n",
       "z          0.812458 -0.602663  1.000000  0.807137 -0.602663   0.847163\n",
       "x*x        0.997947 -0.209289  0.807137  1.000000 -0.209289   0.997457\n",
       "2*y       -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123\n",
       "2*z+3*x*x  0.996252 -0.261123  0.847163  0.997457 -0.261123   1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = d.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. plot heat map of correlation matrix using seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = d.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding the best model for the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Train Logistic regression on data(X,Y) that we have created in the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for hyperpaerameter C =  {'C': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "gsc = GridSearchCV(estimator = LogisticRegression(),param_grid={\n",
    "            'C': [0.0001,0.001,0.1,1,10,100]})\n",
    "gsc.fit(X,Y)\n",
    "\n",
    "best_C = gsc.best_params_\n",
    "print(\"Best value for hyperpaerameter C = \",best_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Creat a new Logistic regression with the best alpha(search for how to get the best hyper parameter value), name the best model as 'best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LogisticRegression(C = 0.0001)\n",
    "best_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Getting the weights with the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. train the 'best_model' with X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LogisticRegression(C = 0.0001)\n",
    "best_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Check the accuracy of the model 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find accuracy of the best_model the data is divided into train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the best_model =  1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(C = 0.0001)\n",
    "best_model.fit(X_train,y_train)\n",
    "f = best_model.predict(X_test)\n",
    "\n",
    "# Finding model best accuracy\n",
    "a = 0\n",
    "for i in range(len(y_test)):\n",
    "    if f[i] == y_test[i]:\n",
    "        a = a + 1\n",
    "best_model_accuracy = a/len(y_test)\n",
    "print(\"The accuracy of the best_model = \",best_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Get the weights W using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0032228  -0.00297691  0.0042705   0.00316198 -0.00297691  0.0033614\n",
      "   0.00274008]]\n"
     ]
    }
   ],
   "source": [
    "best_w = best_model.coef_\n",
    "print(best_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modifying original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a noise of order 10^-2 to each element of X \n",
    "noise = 0.01\n",
    "X_ = X\n",
    "for i in X_:\n",
    "    for j in range(len(i)):\n",
    "        i[j] = i[j] + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Train the same 'best_model' with data (X', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Check the accuracy of the model 'best_model_accuracy_edited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, Y, test_size=0.10, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the edited best_model =  1.0\n"
     ]
    }
   ],
   "source": [
    "f = best_model.predict(X_test)\n",
    "\n",
    "# Finding model best accuracy\n",
    "a = 0\n",
    "for i in range(len(y_test)):\n",
    "    if f[i] == y_test[i]:\n",
    "        a = a + 1\n",
    "best_model_accuracy_edited = a/len(y_test)\n",
    "print(\"The accuracy of the edited best_model = \",best_model_accuracy_edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Get the weights W' using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00359629 -0.00341974  0.00479981  0.00355268 -0.00341974  0.00377694\n",
      "   0.00316971]]\n"
     ]
    }
   ],
   "source": [
    "best_w_edited = best_model.coef_\n",
    "print(best_w_edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Checking deviations in metric and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "difference_between_accuracy = best_model_accuracy_edited - best_model_accuracy\n",
    "print(difference_between_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. find the absolute change between each value of W and W' ==> |(W-W')|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00037349 0.00044283 0.00052931 0.00039071 0.00044283 0.00041554\n",
      "  0.00042963]]\n",
      "[0.0003734878239709475, 0.00044282932785529635, 0.0005293051880613381, 0.000390705664662731, 0.00044282932785529635, 0.0004155429405460864, 0.0004296265386969523]\n"
     ]
    }
   ],
   "source": [
    "difference_between_w = np.absolute(best_w - best_w_edited)\n",
    "print(difference_between_w)\n",
    "\n",
    "# converting into list\n",
    "difference_between_w_list = []\n",
    "for i in difference_between_w[0]:\n",
    "    difference_between_w_list.append(i)\n",
    "print(difference_between_w_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. print the top 4 features which have higher % change in weights compare to the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum = []\n",
    "for col in data.columns: \n",
    "    if col != 'target':\n",
    "        colum.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.0003734878239709475, 'y': 0.00044282932785529635, 'z': 0.0005293051880613381, 'x*x': 0.000390705664662731, '2*y': 0.00044282932785529635, '2*z+3*x*x': 0.0004155429405460864, 'w': 0.0004296265386969523}\n"
     ]
    }
   ],
   "source": [
    "keys  = colum\n",
    "values = difference_between_w_list\n",
    "dictionary = dict(zip(keys,values))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 4 features which have higher % change in weights:\n",
      "('z', 0.0005293051880613381)\n",
      "('y', 0.00044282932785529635)\n",
      "('2*y', 0.00044282932785529635)\n",
      "('w', 0.0004296265386969523)\n"
     ]
    }
   ],
   "source": [
    "#sorting of dictionry : https://www.saltycrane.com/blog/2007/09/how-to-sort-python-dictionary-by-keys/\n",
    "sort_dict = sorted(dictionary.items(), key=lambda item: item[1],reverse= True)[:4]\n",
    "print(\"top 4 features which have higher % change in weights:\")\n",
    "for i in sort_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding the best model for the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Train Linear SVM on data(X,Y) that we have created in the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel = 'linear')\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for hyperpaerameter C =  {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "gsc = GridSearchCV(estimator = SVC(kernel = 'linear'),param_grid={\n",
    "            'C': [0.0001,0.001,0.1,1,10,100]})\n",
    "gsc.fit(X,Y)\n",
    "\n",
    "best_C = gsc.best_params_\n",
    "print(\"Best value for hyperpaerameter C = \",best_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Creat a new Logistic regression with the best alpha(search for how to get the best hyper parameter value), name the best model as 'best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SVC(kernel = 'linear',C = 0.1)\n",
    "best_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Getting the weights with the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. train the 'best_model' with X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SVC(kernel = 'linear',C = 0.1)\n",
    "best_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Check the accuracy of the model 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find accuracy of the best_model the data is divided into train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the best_model =  1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = SVC(kernel = 'linear',C = 0.1)\n",
    "best_model.fit(X_train,y_train)\n",
    "f = best_model.predict(X_test)\n",
    "\n",
    "# Finding model best accuracy\n",
    "a = 0\n",
    "for i in range(len(y_test)):\n",
    "    if f[i] == y_test[i]:\n",
    "        a = a + 1\n",
    "best_model_accuracy = a/len(y_test)\n",
    "print(\"The accuracy of the best_model = \",best_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Get the weights W using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20610805 -0.29447692  0.66719643  0.18621623 -0.29447692  0.2481484\n",
      "   0.09723715]]\n"
     ]
    }
   ],
   "source": [
    "best_w = best_model.coef_\n",
    "print(best_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modifying original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.01\n",
    "X_ = X\n",
    "for i in X_:\n",
    "    for j in range(len(i)):\n",
    "        i[j] = i[j] + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Train the same 'best_model' with data (X', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Check the accuracy of the model 'best_model_accuracy_edited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, Y, test_size=0.10, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the edited best_model =  1.0\n"
     ]
    }
   ],
   "source": [
    "f = best_model.predict(X_test)\n",
    "\n",
    "# Finding model best accuracy\n",
    "a = 0\n",
    "for i in range(len(y_test)):\n",
    "    if f[i] == y_test[i]:\n",
    "        a = a + 1\n",
    "best_model_accuracy_edited = a/len(y_test)\n",
    "print(\"The accuracy of the edited best_model = \",best_model_accuracy_edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Get the weights W' using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20595134 -0.29522977  0.66738522  0.18607665 -0.29522977  0.24804557\n",
      "   0.09666126]]\n"
     ]
    }
   ],
   "source": [
    "best_w_edited = best_model.coef_\n",
    "print(best_w_edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Checking deviations in metric and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "difference_between_accuracy = best_model_accuracy_edited - best_model_accuracy\n",
    "print(difference_between_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. find the absolute change between each value of W and W' ==> |(W-W')|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0003734878239709475, 0.00044282932785529635, 0.0005293051880613381, 0.000390705664662731, 0.00044282932785529635, 0.0004155429405460864, 0.0004296265386969523]\n"
     ]
    }
   ],
   "source": [
    "difference_between_w = np.absolute(best_w - best_w_edited)\n",
    "print(difference_between_w_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. print the top 4 features which have higher % change in weights compare to the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum = []\n",
    "for col in data.columns: \n",
    "    if col != 'target':\n",
    "        colum.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.0003734878239709475, 'y': 0.00044282932785529635, 'z': 0.0005293051880613381, 'x*x': 0.000390705664662731, '2*y': 0.00044282932785529635, '2*z+3*x*x': 0.0004155429405460864, 'w': 0.0004296265386969523}\n"
     ]
    }
   ],
   "source": [
    "keys  = colum\n",
    "values = difference_between_w_list\n",
    "dictionary = dict(zip(keys,values))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 4 features which have higher % change in weights:\n",
      "('z', 0.0005293051880613381)\n",
      "('y', 0.00044282932785529635)\n",
      "('2*y', 0.00044282932785529635)\n",
      "('w', 0.0004296265386969523)\n"
     ]
    }
   ],
   "source": [
    "#sorting of dictionry : https://www.saltycrane.com/blog/2007/09/how-to-sort-python-dictionary-by-keys/\n",
    "sort_dict = sorted(dictionary.items(), key=lambda item: item[1],reverse= True)[:4]\n",
    "print(\"top 4 features which have higher % change in weights:\")\n",
    "for i in sort_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "8D_LR_SVM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
